<!doctype html>
<html lang="zh_cn" itemscope itemtype="http://schema.org/Person">
<head>
            <meta charset="utf-8">
        <!-- Site Meta Data -->
        <title>Python网络爬虫基础</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="">
        <meta name="author" content="邱彼郑楠">

        <link rel="shortcut icon" href="/extras/favicon-32x32.png">

        <!-- schema.org -->
        <meta itemprop="name" content="小崔说数">
        <meta itemprop="image" content="">
        <meta itemprop="description" content="">

        <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,600,700' rel='stylesheet' type='text/css'>
        <!-- Style Meta Data -->
        <link rel="stylesheet" href="/theme/css/style.css" type="text/css"/>
        <link rel="stylesheet" href="/theme/css/pygments.css" type="text/css"/>

        <!-- Feed Meta Data -->

        <!-- Weibo Feed -->
        <meta name="weibo:card" content="summary">
        <meta name="weibo:site" content="shushuofengyun">
        <meta name="weibo:image" content="">
        
        <!-- MathJax Supported -->
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js"></script>
        <script>
            MathJax.Hub.Config({
                config: ["MMLorHTML.js"],
                extensions: ["tex2jax.js"],
                jax: ["input/TeX", "output/HTML-CSS", "output/NativeMML"],
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true
                },
                TeX: {
                    extensions: ["AMSmath.js", "AMSsymbols.js"],
                    TagSide: "right",
                    TagIndent: ".8em",
                    MultLineWidth: "85%",
                    equationNumbers: {
                    autoNumber: "AMS",
                },
                unicode: {
                    fonts: "STIXGeneral,'Arial Unicode MS'"
                }
            },
            displayAlign: "center",
            showProcessingMessages: false,
            messageStyle: 'none'
            });
        </script>

        <!-- Prohibit F12, Ctrl+Shift+I, Ctrl+U -->
        <script type="text/javascript">
            document.onkeydown = function () {
                // keyCode = 123 is F12
                // keyCode = 73 is Ctrl + Shift + I
                // keyCode = 85 is Ctrl + U
                if (window.event && (window.event.keyCode == 123 || window.event.keyCode == 73 || window.event.keyCode == 85)) {
                    event.keyCode = 0;
                    event.returnValue = false;
                    return false;
                }
            };
        </script>

    <meta name="weibo:creator" content="shushuofengyun">
    <meta name="weibo:url" content="/python-crawler.html">
    <meta name="weibo:title" content="小崔说数 ~ Python网络爬虫基础">
    <meta name="weibo:description" content="现如今，生活中的信息越来越多，而我们获取信息的来源不止通过浏览网页这一种途径，还可以通过网络爬虫进行实现。两天的时间，结合一些实例，我基本掌握了 Python 网络爬虫的能力，通过这篇博客来记录学到的爬虫知识。 首先，要提到的一点就是robots协议，这是一个网络爬虫排除标准。在这个协议中，告知网络爬虫哪些页面可以抓取，哪些不能。网络爬虫是有一定的风险的，可能会造成性能骚扰、法律风险和隐私泄露，所以我们要遵守各个网站的robots协议。我们在爬取网站之前，最好先看看这个网站有没有robots协议，没有的情况下就可以放心地爬取信息，有robots协议的情况下就应该遵守。如果是自己练习，类人行为可不参考Robots协议。 本文主要介绍 Python 中的 requests 库，bs4 库和 re 库进行爬虫，并给出一个简单的爬取大学排名的实战项目。 Requests库 Requests库的7个主要方法： 方法 说明 requests.request() 构造一个请求，支撑以下各方法的基础方法 requests.get() 获取HTML网页的主要方法，对应于HTTP的GET requests …">

    <!-- Facebook Meta Data -->
    <meta property="og:title" content="小崔说数 ~ Python网络爬虫基础"/>
    <meta property="og:description" content="现如今，生活中的信息越来越多，而我们获取信息的来源不止通过浏览网页这一种途径，还可以通过网络爬虫进行实现。两天的时间，结合一些实例，我基本掌握了 Python 网络爬虫的能力，通过这篇博客来记录学到的爬虫知识。 首先，要提到的一点就是robots协议，这是一个网络爬虫排除标准。在这个协议中，告知网络爬虫哪些页面可以抓取，哪些不能。网络爬虫是有一定的风险的，可能会造成性能骚扰、法律风险和隐私泄露，所以我们要遵守各个网站的robots协议。我们在爬取网站之前，最好先看看这个网站有没有robots协议，没有的情况下就可以放心地爬取信息，有robots协议的情况下就应该遵守。如果是自己练习，类人行为可不参考Robots协议。 本文主要介绍 Python 中的 requests 库，bs4 库和 re 库进行爬虫，并给出一个简单的爬取大学排名的实战项目。 Requests库 Requests库的7个主要方法： 方法 说明 requests.request() 构造一个请求，支撑以下各方法的基础方法 requests.get() 获取HTML网页的主要方法，对应于HTTP的GET requests …"/>
    <meta property="og:image" content=""/>
</head>

<!-- Prohibit copy and right click -->
<body oncontextmenu="return false" onselectstart="return false">
<!-- Sidebar -->
<aside>
    <!--<center><a href=""><img id="avatar" src=""></a></center>-->
    <h1>小崔说数</h1>
        <p>数学知识分享和Python学习</p>
    <br>

    <nav class="nav">
        <ul class="list-bare">

                <li><a class="nav__link" href="">Home</a></li>
                <li><a class="nav__link" href="/pages/about.html">About</a></li>
                <li><a class="nav__link" href="/categories.html">Categories</a></li>


        </ul>
    </nav>

    <p class="social">
                <a href="https://github.com/KristopherTsui" target="_blank"><img
                        src="/theme/images/icons/github.png"></a>
                <a href="https://weibo.com/shushuofengyun" target="_blank"><img
                        src="/theme/images/icons/weibo.png"></a>
    </p>


        <h2 class="blog_roll_link"><br/>BLOGROLLS</h2>
        <ul class="navbar">
                <li><a href="http://www.amss.ac.cn">中国科学院数学与系统科学研究院</a></li>
                <li><a href="http://ymsc.tsinghua.edu.cn/cn">丘成桐数学科学中心</a></li>
        </ul>

</aside>

<!-- Content -->
<article>
    <section id="content">
        <article>
            <h2 class="post_title post_detail"><a href="/python-crawler.html" rel="bookmark"
                                                  title="Permalink to Python网络爬虫基础">Python网络爬虫基础</a></h2>
            <div class="entry-content blog-post">
                <p>现如今，生活中的信息越来越多，而我们获取信息的来源不止通过浏览网页这一种途径，还可以通过网络爬虫进行实现。两天的时间，结合一些实例，我基本掌握了 Python 网络爬虫的能力，通过这篇博客来记录学到的爬虫知识。</p>
<p>首先，要提到的一点就是<strong>robots协议</strong>，这是一个网络爬虫排除标准。在这个协议中，告知网络爬虫哪些页面可以抓取，哪些不能。网络爬虫是有一定的风险的，可能会造成性能骚扰、法律风险和隐私泄露，所以我们要遵守各个网站的robots协议。我们在爬取网站之前，最好先看看这个网站有没有robots协议，没有的情况下就可以放心地爬取信息，有robots协议的情况下就应该遵守。如果是自己练习，类人行为可不参考Robots协议。</p>
<p>本文主要介绍 Python 中的 <code>requests</code> 库，<code>bs4</code> 库和 <code>re</code> 库进行爬虫，并给出一个简单的爬取大学排名的实战项目。</p>
<h2>Requests库</h2>
<p>Requests库的7个主要方法：</p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code>requests.request()</code></td>
<td align="center">构造一个请求，支撑以下各方法的基础方法</td>
</tr>
<tr>
<td align="center"><code>requests.get()</code></td>
<td align="center">获取HTML网页的主要方法，对应于HTTP的GET</td>
</tr>
<tr>
<td align="center"><code>requests.head()</code></td>
<td align="center">获取HTML网页头信息的方法，对应于HTTP的HEAD</td>
</tr>
<tr>
<td align="center"><code>requests.post()</code></td>
<td align="center">向HTML网页提交POST请求的方法，对应于HTTP的POST</td>
</tr>
<tr>
<td align="center"><code>requests.put()</code></td>
<td align="center">向HTML网页提交PUT请求的方法，对应于HTTP的PUT</td>
</tr>
<tr>
<td align="center"><code>requests.patch()</code></td>
<td align="center">向HTML网页提交局部修改请求，对应于HTTP的PATCH</td>
</tr>
<tr>
<td align="center"><code>requests.delete()</code></td>
<td align="center">向HTML页面提交删除请求，对应于HTTP的DELETE</td>
</tr>
</tbody>
</table>
<h3>Get()方法</h3>
<p>requests库中的 <code>get()</code> 方法是最常用的方法。<code>r = requests.get(url)</code> 构造一个向服务器请求资源的Request对象，返回一个包含服务器资源的Response对象。它的参数有 <code>url</code> 和其它12个控制访问的参数。控制参数中比较常用的有 <code>headers</code> 和 <code>proxies</code>，分别控制头信息和 IP 地址。使用Python网络爬虫，头信息的 <code>User-Agent</code> 为 <code>python-requests/2.11.1</code>。由于很多网站对网络爬虫进行限制，会检查来访 HTTP 协议头的 <code>User-Agent</code> 域，只响应浏览器或友好爬虫的访问。因此大多数情况下，我们需要修改该域为 <code>Mozilla/5.0</code> 模拟浏览器发起访问，否则会访问失败。<code>proxies</code> 可以设置代理 IP 地址，避免自己的 IP 地址被禁，比较好的保护信息。</p>
<p>下面我们重点来谈一谈 <code>get()</code> 方法返回的 <code>Responce</code> 对象，其包含服务器返回的所有信息，也包含请求的 <code>Request</code> 信息。它的属性如下表所示：</p>
<table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code>r.status_code</code></td>
<td align="center">HTTP请求的返回状态，200表示连接成功，404表示失败</td>
</tr>
<tr>
<td align="center"><code>r.text</code></td>
<td align="center">HTTP响应内容的字符串形式，即url对应的页面内容</td>
</tr>
<tr>
<td align="center"><code>r.encoding</code></td>
<td align="center">从HTTP header中猜测的响应内容编码方式</td>
</tr>
<tr>
<td align="center"><code>r.apparent_encoding</code></td>
<td align="center">从内容中分析出的响应内容编码方式(备选编码方式)</td>
</tr>
<tr>
<td align="center"><code>r.content</code></td>
<td align="center">HTTP响应内容的二进制形式</td>
</tr>
</tbody>
</table>
<p>对于其中的 <code>r.encoding</code> 和 <code>r.apparent_encoding</code> 两个编码方式：</p>
<ul>
<li><code>r.encoding</code>：如果header中不存在 charset，则认为编码为ISO-8859-1，<code>r.text</code> 根据 <code>r.encoding</code>  显示内容</li>
<li><code>r.apparent_encoding</code>：根据网页内容分析出的编码方式，可以看作是 <code>r.encoding</code> 的备选</li>
</ul>
<h3>Requests库的异常</h3>
<p>在网络连接过程中，有可能会出现以下几种异常情况，合理处理异常是顺利爬虫的关键：</p>
<table>
<thead>
<tr>
<th align="center">异常</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code>requests.ConnectionError</code></td>
<td align="center">网络连接错误异常，如 DNS 查询失败、拒绝连接等</td>
</tr>
<tr>
<td align="center"><code>requests.HTTPError</code></td>
<td align="center">HTTP错误异常</td>
</tr>
<tr>
<td align="center"><code>requests.URLRequired</code></td>
<td align="center">URL缺失异常</td>
</tr>
<tr>
<td align="center"><code>requests.TooManyRedirects</code></td>
<td align="center">超过最大重定向次数，产生重定向异常</td>
</tr>
<tr>
<td align="center"><code>requests.ConnectTimeout</code></td>
<td align="center">连接远程服务器超时异常</td>
</tr>
<tr>
<td align="center"><code>requests.Timeout</code></td>
<td align="center">请求URL超时，产生超时异常</td>
</tr>
</tbody>
</table>
<p>我们在爬虫过程中，主要判断是否成功连接到 url，也就是 <code>r.status_code</code> 是否为 200，可以使用 <code>r.raise_for_status</code>，如果不是200，它会产生异常 <code>requests.HTTPError</code>。<code>r.raise_for_status</code> 在方法内部判断 <code>r.status_code</code> 是否等于200，不需要增加额外的 <code>if</code> 语句，该语句便于利用 <code>try-except</code> 进行异常处理。</p>
<h3>通用代码框架</h3>
<p>到这里，其实我们可以写出一个简单的可以爬取网页的框架：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">requests</span>


<span class="k">def</span> <span class="nf">get_html_text</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">ua</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s2">&quot;Mozilla/5.0&quot;</span><span class="p">}</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">ua</span><span class="p">)</span>
        <span class="n">r</span><span class="o">.</span><span class="n">raise_for_status</span>
        <span class="n">r</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">apparent_encoding</span>
        <span class="k">return</span> <span class="n">r</span><span class="o">.</span><span class="n">text</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;网页：</span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s2">爬取失败!&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;http://www.baidu.com&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">get_html_text</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
</code></pre></div>


<p>对于这个代码框架，可以提升速度的一点是 <code>r.encoding = r.apparent_encoding</code> 语句。因为 <code>r.apparent_eocoding</code> 需要对全部内容进行分析，对时间的消耗较大，所以如果可以从浏览器中获取编码方式，直接修改为目标值即可，可以减少对内容编码方式分析的时间。</p>
<h3>HTTP协议</h3>
<p>HTTP，Hypertext Transfer Protocol，超文本传输协议。HTTP是一个基于”请求与响应“模式的、无状态的应用层协议。HTTP协议采用URL作为定位网络资源的标识，URL格式如下：</p>
<div class="highlight"><pre><span></span><code><span class="err">http://host[:port][path]</span>
</code></pre></div>


<p>其中 <code>host</code> 为合法的Internet主机域名或 IP 地址；<code>port</code> 为端口号，缺省端口为80；<code>path</code> 为请求资源的路径。</p>
<p>HTTP 协议对资源的操作如下表所示：</p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">GET</td>
<td align="center">请求获取 URL 位置的资源</td>
</tr>
<tr>
<td align="center">HEAD</td>
<td align="center">请求获取 URL 位置资源的响应消息报告，即获得该资源的头部信息</td>
</tr>
<tr>
<td align="center">POST</td>
<td align="center">请求向 URL 位置的资源后附加新的数据</td>
</tr>
<tr>
<td align="center">PUT</td>
<td align="center">请求向 URL 位置存储一个资源，覆盖原 URL 位置的资源</td>
</tr>
<tr>
<td align="center">PATCH</td>
<td align="center">请求局部更新 URL 位置的资源，即改变该处资源的部分内容</td>
</tr>
<tr>
<td align="center">DELETE</td>
<td align="center">请求删除 URL 位置存储的资源</td>
</tr>
</tbody>
</table>
<p>HTTP协议中的方法和 <code>Requests</code> 库中的方法一一对应并且保持功能一致性。</p>
<p>这些方法应用的并不多，这里不多介绍，可以去参考相关的文档进行学习。</p>
<h2>Beautiful Soup库</h2>
<p>Beautiful Soup库是解析、遍历、维护”标签树“的功能库。在使用之前，最好对 HTML 有一定的了解。以下面这个标签为例：</p>
<div class="highlight"><pre><span></span><code><span class="p">&lt;</span><span class="nt">p</span> <span class="na">class</span><span class="o">=</span><span class="s">&quot;title&quot;</span><span class="p">&gt;</span> ... <span class="p">&lt;/</span><span class="nt">p</span><span class="p">&gt;</span>
</code></pre></div>


<p>名称 <code>p</code> 是成对出现的，第2个前面要有反斜杠。<code>class="title"</code> 是它的属性，一个标签可以有多个属性。</p>
<p>在调用 BeautifulSoup 的过程中，我们得到一个 BeautifulSoup 类，这个类对应着标签树，也就是一个 HTML/XML 文档的全部内容。另外，我们还需要一个 HTML 的解释器，主要有以下四个解释器，我们使用 <code>bs4</code> 的 HTML 解析器：</p>
<table>
<thead>
<tr>
<th align="center">解释器</th>
<th align="center">使用方法</th>
<th align="center">条件</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code>bs4</code>的HTML解析器</td>
<td align="center"><code>BeautifulSoup(mk, 'html.parser')</code></td>
<td align="center">安装<code>bs4</code>库</td>
</tr>
<tr>
<td align="center"><code>lxml</code>的HTML解析器</td>
<td align="center"><code>BeautifulSoup(mk, 'lxml')</code></td>
<td align="center">安装<code>lxml</code>库</td>
</tr>
<tr>
<td align="center"><code>lxml</code>的XML解析器</td>
<td align="center"><code>BeautifulSoup(mk, 'xml')</code></td>
<td align="center">安装<code>lxml</code>库</td>
</tr>
<tr>
<td align="center"><code>html5lib</code>的解析器</td>
<td align="center"><code>BeautifulSoup(mk,  'html5lib')</code></td>
<td align="center">安装<code>html5lib</code>库</td>
</tr>
</tbody>
</table>
<h3>BeautifulSoup类的基本元素</h3>
<p>BeautifulSoup 类有5个基本元素：</p>
<table>
<thead>
<tr>
<th align="center">基本元素</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">Tag</td>
<td align="center">标签，最基本的信息组织单元，分别用&lt;&gt;和</>标明开头和结尾</td>
</tr>
<tr>
<td align="center">Name</td>
<td align="center">标签的名字，<code>&lt;p&gt;...&lt;/p&gt;</code> 的名字是'p'，格式：<code>&lt;tag&gt;.name</code></td>
</tr>
<tr>
<td align="center">Attributes</td>
<td align="center">标签的属性，字典形式组织，格式：<code>&lt;tag&gt;.attrs</code></td>
</tr>
<tr>
<td align="center">NavigableString</td>
<td align="center">标签内非属性字符串，&lt;&gt;...</>中字符串，格式：<code>&lt;tag&gt;.string</code></td>
</tr>
<tr>
<td align="center">Comment</td>
<td align="center">标签内字符串的注释部分，一种特殊的Comment类型</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>任何存在于HTML语法中的标签都可以用 <code>BeautifulSoup.&lt;tag&gt;</code> 访问获得，当HTML文档中存在多个相同 <code>&lt;tag&gt;</code> 对应内容时，<code>BeautifulSoup.&lt;tag&gt;</code> 返回第一个。</p>
</li>
<li>
<p>每个 <code>&lt;tag&gt;</code> 都有自己的名字，通过 <code>&lt;tag&gt;.name</code>  获取，为字符串类型。</p>
</li>
<li>
<p>一个 <code>&lt;tag&gt;</code> 可以有0或多个属性，为字典类型。</p>
</li>
<li>NavigableString可以跨越多个层次。</li>
</ul>
<h3>基于<code>bs4</code>库的HTML内容遍历方法</h3>
<p>有三种遍历方式，分别为下行遍历、上行遍历和平行遍历。</p>
<p>使用下行遍历，我们有以下属性：</p>
<table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code>.contents</code></td>
<td align="center">子节点的列表，将 <code>&lt;tag&gt;</code> 所有儿子节点存入列表</td>
</tr>
<tr>
<td align="center"><code>.children</code></td>
<td align="center">子节点的迭代类型，与 <code>.contents</code> 类似，用于循环遍历儿子节点</td>
</tr>
<tr>
<td align="center"><code>.descendants</code></td>
<td align="center">子孙节点的迭代类型，包含所有子孙节点，用于循环遍历</td>
</tr>
</tbody>
</table>
<p>由于 BeautifulSoup 类是标签树的根节点，遍历儿子节点或者子孙节点代码如下：</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>

<span class="c1"># 遍历儿子节点</span>
<span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">soup</span><span class="o">.</span><span class="n">body</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>

<span class="c1"># 遍历子孙节点</span>
<span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">soup</span><span class="o">.</span><span class="n">body</span><span class="o">.</span><span class="n">descendants</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
</code></pre></div>


<p>使用上行遍历，我们有以下属性：</p>
<table>
<thead>
<tr>
<th>属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>.parent</code></td>
<td align="center">节点的父亲标签</td>
</tr>
<tr>
<td><code>.parents</code></td>
<td align="center">节点先辈标签的迭代类型，用于循环遍历先辈节点</td>
</tr>
</tbody>
</table>
<p>由于所有的先辈节点包括 soup 本身，所以要区别对待。</p>
<p>使用平行遍历 ，我们有以下属性：</p>
<table>
<thead>
<tr>
<th>属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>.next_sibling</code></td>
<td align="center">返回按照 HTML 文本顺序的下一个平行节点标签</td>
</tr>
<tr>
<td><code>.previous_sibling</code></td>
<td align="center">返回按照 HTML 文本顺序的上一个平行节点标签</td>
</tr>
<tr>
<td><code>.next_siblings</code></td>
<td align="center">迭代类型，返回按照 HTML 文本顺序的后续所有平行节点标签</td>
</tr>
<tr>
<td><code>.previous_siblings</code></td>
<td align="center">迭代类型，返回按照 HTML 文本顺序的前序所有平行节点标签</td>
</tr>
</tbody>
</table>
<p>注意，平行遍历发生在同一个父节点下的各节点间。</p>
<p>最后，补充一个控制 html 格式输出的方法 <code>.prettity()</code>，它可以让HTML内容更加友好的显示。它也可用于标签的格式输出，其原理为在内容中增加 <code>\n</code>。</p>
<h2>Re(正则表达式)库入门</h2>
<p>正则表达式是用来简介表达一组字符串的表达式，是一种通用的字符串表达框架。正则表达式是一种针对字符串表达“简洁”和“特征”思想的工具，可以用来判断某字符串的特征归属。</p>
<p>正则表达式语法由字符和操作符构成。常用的操作符如下表所示：</p>
<table rules="all" border="1">
    <tr align="center">
        <th>操作符</th>
        <th>说明</th>
        <th>实例</th>
    </tr>
    <tr align="center">
        <th>.</th>
        <th>表示任何单个字符</th>
        <th></th>
    </tr>
    <tr align="center">
        <th>[ ]</th>
        <th>字符集，对单个字符给出取值范围</th>
        <th>[abc]表示a、b、c，[a-z]表示a到z单个字符</th>
    </tr>
    <tr align="center">
        <th>[^ ]</th>
        <th>非字符集，对单个字符给出  排除范围</th>
        <th>[^abc]表示非a或b或c的单个字符</th>
    </tr>
    <tr align="center">
        <th>*</th>
        <th>前一个字符0次或无限次扩展</th>
        <th>abc* 表示 ab、abc、abcc、abccc等</th>
    </tr>
    <tr align="center">
        <th>+</th>
        <th>前一个字符1次或无限次扩展</th>
        <th>abc+ 表示 abc、abcc、abccc等</th>
    </tr>
    <tr align="center">
        <th>?</th>
        <th>前一个字符0次或1次扩展</th>
        <th>abc? 表示 ab、abc</th>
    </tr>
    <tr align="center">
        <th>|</th>
        <th>左右表达式任意一个</th>
        <th>abc|def 表示 abc、def</th>
    </tr>
    <tr align="center">
        <th>{m}</th>
        <th>扩展前一个字符m次</th>
        <th>ab{2}c表示abbc</th>
    </tr>
    <tr align="center">
        <th>{m,n}</th>
        <th>扩展前一个字符m至n次(含n)</th>
        <th>ab{1,2}c表示abc、abbc</th>
    </tr>
    <tr align="center">
        <th>^</th>
        <th>匹配字符串开头</th>
        <th>^abc表示abc且在一个字符串的开头</th>
    </tr>
    <tr align="center">
        <th>$</th>
        <th>匹配字符串结尾</th>
        <th>abc$表示abc且在一个字符串的结尾</th>
    </tr>
    <tr align="center">
        <th>( )</th>
        <th>分组标记，内部只能使用 | 操作符</th>
        <th>(abc)表示abc，(abc|def)表示abc、def</th>
    </tr>
    <tr align="center">
        <th>\d</th>
        <th>数字，等价于[0-9]</th>
        <th></th>
    </tr>
    <tr align="center">
        <th>\w</th>
        <th>单词字符，等价于[A-Za-z0-9_]</th>
        <th></th>
    </tr>
</table>

<p>Re库是Python的标准库，主要用于字符串匹配。Re库采用raw string类型表示正则表达式，表示为 <code>r'text'</code>，raw string 是不包含对转义符再次转义的字符串；当然也可以采用 string 类型表示正则表达式，但更繁琐，所以建议当正则表达式包含转义符时，使用 raw string。</p>
<h3>Re库主要功能函数</h3>
<table>
<thead>
<tr>
<th align="center">函数</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code>re.search()</code></td>
<td align="center">在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象</td>
</tr>
<tr>
<td align="center"><code>re.match()</code></td>
<td align="center">从一个字符串的开始位置起匹配正则表达式，返回match对象</td>
</tr>
<tr>
<td align="center"><code>re.findall()</code></td>
<td align="center">搜索字符串，以列表类型返回全部能匹配的子串</td>
</tr>
<tr>
<td align="center"><code>re.split()</code></td>
<td align="center">将一个字符串按照正则表达式匹配结果进行分割，返回列表类型</td>
</tr>
<tr>
<td align="center"><code>re.finditer()</code></td>
<td align="center">搜索字符串，返回一个匹配结果的迭代类型，每个迭代类型时match对象</td>
</tr>
<tr>
<td align="center"><code>re.sub()</code></td>
<td align="center">在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串</td>
</tr>
</tbody>
</table>
<p>这些函数主要有三个参数，分别为：</p>
<ul>
<li>pattern：正则表达式的字符串或原生字符串表示</li>
<li>string：待匹配字符串</li>
<li>flags：正则表达式使用时的控制标记</li>
</ul>
<p>Re库的使用可以分为函数式用法和面向对象用法两种：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">re</span>

<span class="c1"># 函数式用法：一次性操作</span>
<span class="n">rst</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[1-9]\d</span><span class="si">{5}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;BIT 100081&#39;</span><span class="p">)</span>

<span class="c1"># 面向对象用法：编译后的多次操作</span>
<span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;[1-9]\d</span><span class="si">{5}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">rst</span> <span class="o">=</span> <span class="n">pat</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="s1">&#39;BIT 100081&#39;</span><span class="p">)</span>
</code></pre></div>


<h3>Re库的Match对象</h3>
<p>Match对象是一次匹配的结果，包含匹配的很多信息，它的属性如下表所示：</p>
<table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code>.string</code></td>
<td align="center">待匹配的文本</td>
</tr>
<tr>
<td align="center"><code>.re</code></td>
<td align="center">匹配时使用的patter对象(正则表达式)</td>
</tr>
<tr>
<td align="center"><code>.pos</code></td>
<td align="center">正则表达式搜索文本的开始位置</td>
</tr>
<tr>
<td align="center"><code>.endpos</code></td>
<td align="center">正则表达式搜索文本的结束位置</td>
</tr>
</tbody>
</table>
<h4>Match对象的方法</h4>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><code>.group(0)</code></td>
<td align="center">获得匹配后的字符串</td>
</tr>
<tr>
<td align="center"><code>.start()</code></td>
<td align="center">匹配字符串在原始字符串的开始位置</td>
</tr>
<tr>
<td align="center"><code>.end()</code></td>
<td align="center">匹配字符串在原始字符串的结束位置</td>
</tr>
<tr>
<td align="center"><code>.span()</code></td>
<td align="center">返回(.start(), .end())</td>
</tr>
</tbody>
</table>
<p>Re库默认采用贪婪匹配，即输出匹配最长的子串。那么如何输出最短的子串呢？</p>
<table>
<thead>
<tr>
<th align="center">操作符</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">*？</td>
<td align="center">前一个字符0次或无限次扩展，最小匹配</td>
</tr>
<tr>
<td align="center">+？</td>
<td align="center">前一个字符1次或无限次扩展，最小匹配</td>
</tr>
<tr>
<td align="center">？？</td>
<td align="center">前一个字符0次或1次扩展，最小匹配</td>
</tr>
<tr>
<td align="center" m_n="m,n"></td>
<td align="center">扩展前一个字符m至n次(含n)，最小匹配</td>
</tr>
</tbody>
</table>
<p>只要长度输出可能不同的，都可以通过在操作符后增加?变成最小匹配。</p>
<h2>爬取大学排名实例</h2>
<p>最后要介绍一个简单一些的使用Python爬取大学排名的实例。这里我们要用到requests库和bs4库。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">bs4</span>
</code></pre></div>


<p>将爬取大学排名分为3步实现，分别为获取<a href="http://zuihaodaxue.com/zuihaodaxuepaiming-zongbang-2020.html">最好大学网</a>的HTML信息，分析HTML并将大学排名信息储存在列表中，打印大学排名信息。</p>
<p>获取HTML信息采用前面给出的爬虫框架，即</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_html_text</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">ua</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0&#39;</span><span class="p">}</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">ua</span><span class="p">)</span>
        <span class="n">r</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
        <span class="n">r</span><span class="o">.</span><span class="n">encoding</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">apparent_encoding</span>
        <span class="k">return</span> <span class="n">r</span><span class="o">.</span><span class="n">text</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;网页：</span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s1">爬取失败!&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>
</code></pre></div>


<p>下面我们在浏览器中查看该网页的源代码：</p>
<div style="text-align: center;">
<img src="https://cdn.jsdelivr.net/gh/KristopherTsui/FigureBed/images/%E6%9C%80%E5%A5%BD%E5%A4%A7%E5%AD%A6%E7%BD%91HTML%E6%BA%90%E4%BB%A3%E7%A0%81.png" alt="网页源代码" title="网页源代码" />
</div>

<p>从源代码中我们可以知道，排名信息全部都储存在<code>&lt;tbody&gt;</code>这个标签中，所以在使用bs4库中的BeautifulSoup函数处理过html后，寻找<code>&lt;tbody</code> 标签的孩子，每一个孩子储存着一个学校的信息，在<code>&lt;tr&gt;</code>标签中；每个学校的信息又有4项，分别储存在<code>&lt;td&gt;</code>标签中。遍历<code>&lt;tr&gt;</code>标签，将每个<code>&lt;tr&gt;</code>标签的<code>&lt;td&gt;</code>子标签的信息添加到列表中即可。</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">fill_univ_list</span><span class="p">(</span><span class="n">univ_list</span><span class="p">,</span> <span class="n">html</span><span class="p">):</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">tr</span> <span class="ow">in</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;tbody&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tr</span><span class="p">,</span> <span class="n">bs4</span><span class="o">.</span><span class="n">element</span><span class="o">.</span><span class="n">Tag</span><span class="p">):</span>
            <span class="n">tds</span> <span class="o">=</span> <span class="n">tr</span><span class="p">(</span><span class="s1">&#39;td&#39;</span><span class="p">)</span>
            <span class="n">univ_list</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">tds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">tds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">string</span><span class="p">,</span> <span class="n">tds</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">string</span><span class="p">])</span>
</code></pre></div>


<p>第三，我们需要打印排名列表：</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">print_iniv_list</span><span class="p">(</span><span class="n">univ_list</span><span class="p">,</span> <span class="n">num</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;排名&#39;</span><span class="si">:</span><span class="s2">^6</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="s1">&#39;学校排名&#39;</span><span class="si">:</span><span class="s2">^10</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="s1">&#39;总分&#39;</span><span class="si">:</span><span class="s2">^6</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">univ_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">u</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">^6</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">u</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">^10</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="n">u</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">:</span><span class="s2">^6</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>


<p>最后，我们只需要在主函数中调用上面三个函数实现相应的功能即可：</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">mian</span><span class="p">():</span>
    <span class="n">univ_info</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;http://zuihaodaxue.com/zuihaodaxuepaiming-zongbang-2020.html&#39;</span>
    <span class="n">html</span> <span class="o">=</span> <span class="n">get_html_text</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">fill_univ_list</span><span class="p">(</span><span class="n">univ_info</span><span class="p">,</span> <span class="n">html</span><span class="p">)</span>
    <span class="n">print_univ_list</span><span class="p">(</span><span class="n">univ_info</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div>


<p>运行后的结果如下：</p>
<div style="text-align: center;">
<img src="https://cdn.jsdelivr.net/gh/KristopherTsui/FigureBed/images/univ_rank.png" alt="大学排名爬虫结果" title="大学排名爬虫结果" />
</div>
            </div>
            <div class="post_list">
                <span>By </span>
                <a href="/author/qiu-bi-zheng-nan.html">@邱彼郑楠</a>
                <span> in </span>
                <span class="post_category"><a href="/category/python.html" rel="bookmark"
                                               title="Permalink to Python">[ Python ]</a></span>
                <span class="post_date">周四 30 七月 2020</span>
                <div><span>Tags : </span>
                            <span><a href="/tag/pa-chong.html">#爬虫, </a></span>
                            <span><a href="/tag/zheng-ze-biao-da-shi.html">#正则表达式, </a></span>
                </div>

                <div class="entry-social">
                    <span class="weibo"><a target="_blank" rel="nofollow"
                                           onclick="javascript:window.open(this.href, '', 'mrnubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=400,width=700');return false;"
                                           title="Weibo"
                                           href="https://service.weibo.com/share/share.php?url=/python-crawler.html&text=Python网络爬虫基础&via=shushuofengyun"><img
                            src="/theme/images/icons/weibo-s.png"></a></span>

                    <span class="QQ"><a target="_blank" title="QQ" rel="nofollow"
                                              onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=500,width=700');return false;"
                                              href="https://connect.qq.com/widget/shareqq/index.html?url=/python-crawler.html&t=Python网络爬虫基础"><img
                            src="/theme/images/icons/qq-s.png"></a></span>
                    
                    <span class="QZone"><a target="_blank" title="QZone" rel="nofollow"
                                              onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=500,width=700');return false;"
                                              href="https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?url=/python-crawler.html&t=Python网络爬虫基础"><img
                            src="/theme/images/icons/qzone-s.png"></a></span>

                    <span class="mail"><a
                            href="mailto:?subject=Python网络爬虫基础&amp;body=Viens découvrir un article à propos de [Python网络爬虫基础] sur le site de 邱彼郑楠. /python-crawler.html"
                            title="Share by Email" target="_blank"><img
                            src="/theme/images/icons/mail-s.png"></a></span>

                </div>
            </div>

            <!-- Comments -->

                <div class="comments" id="comments">
	                <!--汉化-->
                    <link rel="stylesheet" href="https://billts.site/extra_css/gitment.css">
                    <script src="https://billts.site/js/gitment.js"></script>
                    <div id="gitmentContainer" style="margin-bottom: -19px;"></div>
                    <style>
                        .gitment-container a {
                        border: none;
                        }
                        .comments {
                        margin: 60px 0 0;padding: 0 60px;
                        }
                    </style>
                    <script type="text/javascript">
                        var gitment = new Gitment({
                            id: '<%= article.title %>',
                            title: '<%= article.title %>',
                            owner: 'KristopherTsui',
                            repo: 'KristopherTsui.github.io',
                            oauth: {
                                client_id: 'ca31867b8c45f8812d60',
                                client_secret: 'bfcd43b591f425e7504c5ea3893e4ea98fee3',
                            },
                        })
                        gitment.render('gitmentContainer')
                    </script>
                </div>
        </article>
    </section>
</article>

<!-- Footer -->
    <footer>
        <p>
            Blog powered by <a href="http://getpelican.com/">Pelican</a>,
            which takes great advantage of <a href="http://python.org">Python</a>.
            Theme <a href="https://github.com/parbhat/pelican-blue">Pelican-Blue</a>.
        </p>
    </footer>


<!-- Baidu Share  -->
<script type="text/javascript" id="bdshare_js" data="type=slide&img=6&pos=right" ></script>
<script type="text/javascript" id="bdshell_js"></script>
<script type="text/javascript">
        var bds_config = {"bdTop":289};
        document.getElementById("bdshell_js").src = "http://bdimg.share.baidu.com/static/js/shell_v2.js?cdnversion=" + new Date().getHours();
</script>

</body>
</html>